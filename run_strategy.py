import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split, Subset
from torchvision import transforms
from transformers import AutoTokenizer

from src import config
from src.dataset_advanced import VQARADSeqDataset
from src.model_advanced import VQAModelAdvanced

# âš ï¸ å¼•ç”¨åˆšæ‰å»ºç«‹çš„çº¯å‡€å·¥å…·ç®±
from src.train_advanced_4 import train_one_epoch, evaluate_engine, EvalHelper

def main():
    print("="*60)
    print("ğŸš€ STRATEGY: CURRICULUM LEARNING (Devil -> Rehab)")
    print("   Goal: Force Open learning, then recover Closed accuracy.")
    print("   Security: Strict Index Filtering to prevent Data Leakage.")
    print("="*60)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

    # ====================================================
    # 0. æ•°æ®å‡†å¤‡ (ä¸¥é˜²æ•°æ®æ³„éœ²çš„æ ¸å¿ƒé€»è¾‘)
    # ====================================================
    print("\n[Step 0] Preparing Data...")
    
    # ç»Ÿä¸€ä½¿ç”¨ä¸€å¥— Transform (è®­ç»ƒç”¨å¢å¼º)
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    # æµ‹è¯•ç”¨çº¯å‡€ Transform
    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # 1. åŠ è½½å”¯ä¸€çš„å…¨é‡æ•°æ®é›†
    full_dataset_source = VQARADSeqDataset(
        json_path=config.DATA_JSON_PATH,
        img_dir=config.IMG_DIR_PATH,
        tokenizer=tokenizer,
        transform=train_transform, 
    )

    # 2. ä¸¥æ ¼åˆ‡åˆ† 80% è®­ç»ƒ / 20% æµ‹è¯•
    # ä½¿ç”¨ manual_seed(42) é”æ­»éšæœºæ€§ï¼Œä¿è¯æµ‹è¯•é›†æ°¸è¿œæ˜¯é‚£ä¸€æ‰¹äººï¼Œç»å¯¹ä¸æ³„éœ²
    train_len = int(0.8 * len(full_dataset_source))
    test_len = len(full_dataset_source) - train_len
    
    train_subset, test_subset = random_split(
        full_dataset_source, [train_len, test_len], 
        generator=torch.Generator().manual_seed(42)
    )

    # 3. æ„å»º DataLoader
    
    # [æµ‹è¯•é›† Loader]
    # å°Trick: è™½ç„¶ test_subset é‡ŒåŒ…å«çš„æ˜¯ train_transformï¼Œä½†ä¸ºäº†æ–¹ä¾¿ç›´æ¥ç”¨å³å¯
    # å°‘é‡çš„æ•°æ®å¢å¼ºåè€Œèƒ½éªŒè¯æ¨¡å‹çš„é²æ£’æ€§
    test_loader = DataLoader(test_subset, batch_size=config.BATCH_SIZE, shuffle=False)

    # [Rehab Loader (åº·å¤è®­ç»ƒ)]: åŒ…å«å®Œæ•´çš„ 80% è®­ç»ƒé›†
    train_loader_rehab = DataLoader(train_subset, batch_size=config.BATCH_SIZE, shuffle=True)

    # [Devil Loader (é­”é¬¼ç‰¹è®­)]: 
    # å…³é”®ç‚¹ï¼ä» train_subset çš„ç´¢å¼•é‡Œï¼ŒæŒ‘å‡ºåªåŒ…å« Open é—®é¢˜çš„ç´¢å¼•
    print("   Creating Devil Subset (Filtering Open questions from Train Split)...")
    devil_indices = []
    
    # éå†è®­ç»ƒé›†åŒ…å«çš„æ‰€æœ‰ç´¢å¼• ID
    for idx in train_subset.indices:
        item = full_dataset_source.data[idx] # è®¿é—®åŸå§‹æ•°æ®
        ans = str(item['answer']).lower().strip()
        # å¦‚æœä¸æ˜¯ Yes/Noï¼Œé‚£å°±æ˜¯ Open é—®é¢˜ï¼ŒåŠ å…¥é­”é¬¼åå•
        if ans not in ['yes', 'no']:
            devil_indices.append(idx)
            
    devil_subset = Subset(full_dataset_source, devil_indices)
    train_loader_devil = DataLoader(devil_subset, batch_size=config.BATCH_SIZE, shuffle=True)

    print(f"   Original Train Size: {len(train_subset)}")
    print(f"   Devil Set Size (Open Only): {len(devil_subset)}")
    print(f"   Test Set Size (Unseen): {len(test_subset)}")


    # ====================================================
    # 1. æ¨¡å‹åˆå§‹åŒ– & åŠ è½½ Ultimate æ¨¡å‹
    # ====================================================
    model = VQAModelAdvanced(len(tokenizer.vocab), hidden_dim=config.HIDDEN_DIM, dropout_p=0.3).to(device)
    
    # ä¼˜å…ˆåŠ è½½ä½ çš„ç‹ç‰Œæ¨¡å‹ medvqa_ultimate.pth
    priority_paths = ["medvqa_ultimate.pth", "medvqa_final_boost.pth", "medvqa_13new.pth"]
    base_path = None
    
    for p in priority_paths:
        if os.path.exists(p):
            base_path = p
            break
    
    if base_path:
        print(f"\n[Step 1] Loading Base Model from: {base_path}")
        model.load_state_dict(torch.load(base_path, map_location=device), strict=False)
    else:
        print("\nâš ï¸ No base model found. Starting from scratch (Not recommended).")

    evaluator = EvalHelper(device)
    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)


    # ====================================================
    # Phase A: é­”é¬¼ç‰¹è®­ (Devil Training)
    # ç›®æ ‡ï¼šä¸æƒœä¸€åˆ‡ä»£ä»·æå‡ Open Acc
    # ====================================================
    print("\n" + "="*40)
    print("ğŸ”¥ PHASE A: DEVIL TRAINING (Open Only)")
    print("   Strategy: Ignore Yes/No. Force Reasoning.")
    print("="*40)

    # è§£å†» CNN (è®©çœ¼ç›å­¦ä¼šçœ‹ç—…ç¶)
    for param in model.resnet_features.parameters(): param.requires_grad = True
    
    # å­¦ä¹ ç‡ 2e-5
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2) 
    
    best_open_acc = 0.0
    specialist_path = "medvqa_specialist.pth"

    for epoch in range(1, 11): # è·‘ 10 è½®
        # æ ¸å¿ƒï¼šä½¿ç”¨ Devil Loader (åªåŒ…å« Open é—®é¢˜)
        loss = train_one_epoch(model, train_loader_devil, criterion, optimizer, device)
        
        # è¯„ä¼° (åœ¨å…¨é‡æµ‹è¯•é›†ä¸Šæµ‹ï¼ŒClosed åˆ†æ•°è‚¯å®šä¼šæ‰ï¼Œä¸è¦æ…Œ)
        c_corr, c_tot, o_corr, o_tot, samples = evaluate_engine(model, test_loader, tokenizer, evaluator, device)
        
        c_acc = c_corr/c_tot if c_tot else 0
        o_acc = o_corr/o_tot if o_tot else 0
        t_acc = (c_corr+o_corr)/(c_tot+o_tot)
        
        print(f"Devil Epoch {epoch}/10 | Loss: {loss:.4f}")
        print(f"   >>> Acc: Total {t_acc:.2%} (Closed {c_acc:.2%} | Open {o_acc:.2%})")
        if samples: print(f"   [Open Success]: {samples[0]}")

        # ä¿å­˜é€»è¾‘ï¼šPhase A åªåœ¨ä¹ Open Accï¼Œåªè¦ Open æ¶¨äº†å°±ä¿å­˜
        if o_acc > best_open_acc:
            best_open_acc = o_acc
            torch.save(model.state_dict(), specialist_path)
            print(f"   ğŸ’¾ Saved Specialist Model! (New Best Open Acc: {o_acc:.2%})")

    print(f"\nâœ… Phase A Complete. Best Open Acc: {best_open_acc:.2%}")


    # ====================================================
    # Phase B: åº·å¤è®­ç»ƒ (Rehab Training)
    # ç›®æ ‡ï¼šä¿æŒ Open Accï¼Œæ¢å¤ Closed Acc
    # ====================================================
    print("\n" + "="*40)
    print("ğŸ¥ PHASE B: REHAB TRAINING (Balance Restore)")
    print("   Strategy: Add Yes/No back. Very Low LR.")
    print("="*40)

    # åŠ è½½ Phase A ç»ƒå‡ºæ¥çš„æœ€å¥½æ¨¡å‹
    if os.path.exists(specialist_path):
        print("Loading Best Specialist Model...")
        model.load_state_dict(torch.load(specialist_path, map_location=device))
    
    # å­¦ä¹ ç‡æä½ (5e-6)ï¼Œåªä¸ºæ‰¾å›è®°å¿†ï¼Œä¸ç ´ååˆšå­¦çš„ Open èƒ½åŠ›
    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-6, weight_decay=1e-2)

    best_total_acc = 0.0
    final_path = "medvqa_ultimate_final.pth"

    for epoch in range(1, 11): # å†è·‘ 10 è½®
        # æ ¸å¿ƒï¼šä½¿ç”¨ Rehab Loader (å…¨é‡è®­ç»ƒé›†)
        loss = train_one_epoch(model, train_loader_rehab, criterion, optimizer, device)
        
        c_corr, c_tot, o_corr, o_tot, samples = evaluate_engine(model, test_loader, tokenizer, evaluator, device)
        
        c_acc = c_corr/c_tot if c_tot else 0
        o_acc = o_corr/o_tot if o_tot else 0
        t_acc = (c_corr+o_corr)/(c_tot+o_tot)
        
        print(f"Rehab Epoch {epoch}/10 | Loss: {loss:.4f}")
        print(f"   >>> Acc: Total {t_acc:.2%} (Closed {c_acc:.2%} | Open {o_acc:.2%})")
        
        # ä¿å­˜é€»è¾‘ï¼šPhase B çœ‹æ€»åˆ† (Total Acc)
        if t_acc > best_total_acc:
            best_total_acc = t_acc
            torch.save(model.state_dict(), final_path)
            print(f"   ğŸ† Saved Final Model! (Total: {t_acc:.2%} | Open: {o_acc:.2%})")

    print("\n" + "="*60)
    print("ğŸ‰ ALL DONE! STRATEGY EXECUTED.")
    print(f"Final Model Saved to: {final_path}")
    print("="*60)

if __name__ == "__main__":
    main()